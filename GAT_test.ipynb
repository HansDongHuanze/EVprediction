{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functions as fn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import models\n",
    "import learner\n",
    "import time\n",
    "import GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system configuration\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n",
    "fn.set_seed(seed=2023, flag=True)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "model_name = 'PAG'\n",
    "seq_l = 12\n",
    "pre_l = 6\n",
    "node_l = 247\n",
    "bs = 512\n",
    "p_epoch = 200\n",
    "n_epoch = 1000\n",
    "law_list = np.array([-1.48, -0.74])  # price elasticities of demand for EV charging. Recommend: up to 5 elements.\n",
    "is_train = True\n",
    "mode = 'completed'  # 'simplified' or 'completed'\n",
    "is_pre_train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "occ, prc, adj, col, dis, cap, tim, inf = fn.read_dataset()\n",
    "adj_dense = torch.Tensor(adj)\n",
    "adj_dense_cuda = adj_dense.to(device)\n",
    "adj_sparse = adj_dense.to_sparse_coo().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset division\n",
    "train_occupancy, valid_occupancy, test_occupancy = fn.division(occ, train_rate=0.6, valid_rate=0.2, test_rate=0.2)\n",
    "nodes = train_occupancy.shape[-1]\n",
    "train_price, valid_price, test_price = fn.division(prc, train_rate=0.6, valid_rate=0.2, test_rate=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "train_dataset = fn.CreateDataset(train_occupancy, train_price, seq_l, pre_l, device, adj_dense)\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
    "valid_dataset = fn.CreateDataset(valid_occupancy, valid_price, seq_l, pre_l, device, adj_dense)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=len(valid_occupancy), shuffle=False)\n",
    "test_dataset = fn.CreateDataset(test_occupancy, test_price, seq_l, pre_l, device, adj_dense)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_occupancy), shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setting\n",
    "model = GAT.GAT_Multi(seq_l, 2, 1, 0, 0.2, 1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.00001)\n",
    "\n",
    "loss_function = torch.nn.MSELoss()\n",
    "valid_loss = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_train is True:\n",
    "    model.train()\n",
    "    if is_pre_train is True:\n",
    "        if mode == 'simplified':  # a simplified way of physics-informed meta-learning\n",
    "            model = learner.fast_learning(law_list, model, model_name, p_epoch, bs, train_occupancy, train_price, seq_l, pre_l, device, adj_dense)\n",
    "\n",
    "        elif mode == 'completed': # the completed process\n",
    "            model = learner.physics_informed_meta_learning(law_list, model, model_name, p_epoch, bs, train_occupancy, train_price, seq_l, pre_l, device, adj_dense)\n",
    "        else:\n",
    "            print(\"Mode error, skip the pre-training process.\")\n",
    "\n",
    "    for epoch in tqdm(range(n_epoch), desc='Fine-tuning'):\n",
    "        for j, data in enumerate(train_loader):\n",
    "            '''\n",
    "            occupancy = (batch, seq, node)\n",
    "            price = (batch, seq, node)\n",
    "            label = (batch, node)\n",
    "            '''\n",
    "            model.train()\n",
    "            occupancy, price, label = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(occupancy, adj_dense_cuda)\n",
    "            loss = loss_function(predict, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        for j, data in enumerate(valid_loader):\n",
    "            '''\n",
    "            occupancy = (batch, seq, node)\n",
    "            price = (batch, seq, node)\n",
    "            label = (batch, node)\n",
    "            '''\n",
    "            model.train()\n",
    "            occupancy, price, label = data\n",
    "            predict = model(occupancy, adj_dense_cuda)\n",
    "            loss = loss_function(predict, label)\n",
    "            if loss.item() < valid_loss:\n",
    "                valid_loss = loss.item()\n",
    "                torch.save(model, './checkpoints' + '/' + model_name + '_' + str(pre_l) + '_bs' + str(bs) + '_' + mode + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./checkpoints' + '/' + model_name + '_' + str(pre_l) + '_bs' + str(bs) + '_' + mode + '.pt')\n",
    "# test\n",
    "model.eval()\n",
    "result_list = []\n",
    "predict_list = np.zeros([1, adj_dense.shape[1]])\n",
    "label_list = np.zeros([1, adj_dense.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store time and memory usage\n",
    "time_list = []\n",
    "memory_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, data in enumerate(test_loader):\n",
    "    occupancy, price, label = data  # occupancy.shape = [batch, seq, node]\n",
    "    print('occupancy:', occupancy.shape, 'price:', price.shape, 'label:', label.shape)\n",
    "    with torch.no_grad():\n",
    "        # Start time measurement\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Start memory tracking\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()  # Synchronize before measuring\n",
    "            memory_before = torch.cuda.memory_allocated()\n",
    "\n",
    "        predict = model(occupancy, adj_dense_cuda)\n",
    "\n",
    "        # End memory tracking\n",
    "        if torch.cuda.is_available():\n",
    "            memory_after = torch.cuda.memory_allocated()\n",
    "            memory_usage = memory_after - memory_before\n",
    "            memory_list.append(memory_usage / (1024 * 1024))  # Convert bytes to MB\n",
    "        \n",
    "        # End time measurement\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        time_list.append(elapsed_time)\n",
    "\n",
    "        predict = predict.cpu().detach().numpy()\n",
    "        label = label.cpu().detach().numpy()\n",
    "        predict_list = np.concatenate((predict_list, predict), axis=0)\n",
    "        label_list = np.concatenate((label_list, label), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_no_noise = fn.metrics(test_pre=predict_list[1:, :], test_real=label_list[1:, :])\n",
    "result_list.append(output_no_noise)\n",
    "result_df = pd.DataFrame(columns=['MSE', 'RMSE', 'MAPE', 'RAE', 'MAE', 'R2'], data=result_list)\n",
    "result_df.to_csv('./results' + '/' + model_name + '_' + str(pre_l) + 'bs' + str(bs) + '.csv', encoding='gbk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average time and memory usage\n",
    "print(f'Average time per prediction: {np.mean(time_list)} seconds')\n",
    "print(f'Average memory usage per prediction: {np.mean(memory_list)} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import models\n",
    "import torch.nn.functional as F\n",
    "import functions as fn\n",
    "import copy\n",
    "\n",
    "from torch.nn import Transformer, TransformerEncoder, TransformerEncoderLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttentionFuncLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, node_l, dropout, alpha, concat=True):\n",
    "        super(GraphAttentionFuncLayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.concat = concat\n",
    "        self.node_l = node_l\n",
    "\n",
    "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
    "        nn.init.kaiming_normal_(self.W, mode='fan_out', nonlinearity='leaky_relu')\n",
    "        self.a = nn.Parameter(torch.empty(2*out_features, 1))\n",
    "        nn.init.xavier_normal_(self.a, gain=nn.init.calculate_gain('leaky_relu', param=alpha))\n",
    "        self.time_embedding = nn.Parameter(torch.empty(in_features, node_l))\n",
    "        nn.init.xavier_normal_(self.time_embedding, gain=nn.init.calculate_gain('leaky_relu', param=alpha))\n",
    "        self.node_embedding = nn.Parameter(torch.empty(node_l, in_features))\n",
    "        nn.init.xavier_normal_(self.node_embedding, gain=nn.init.calculate_gain('leaky_relu', param=alpha))\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        batch_size, N, _ = input.size() # x = [input, N, in_features]\n",
    "        if adj.dim() == 3:\n",
    "            adj = adj[:,:,1].unsqueeze(2).repeat(1,1,adj.shape[1])  # 扩展为 [batch_size, N, N]\n",
    "        elif adj.size(0) != batch_size:\n",
    "            adj = adj[:,:].unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "\n",
    "        '''\n",
    "        h = torch.matmul(input, self.W)  # [batch_size, N, out_features]\n",
    "\n",
    "        h_repeated1 = h.unsqueeze(2).expand(-1, -1, N, -1)  # [batch_size, N, N, out_features]\n",
    "        h_repeated2 = h.unsqueeze(1).expand(-1, N, -1, -1)  # [batch_size, N, N, out_features]\n",
    "        a_input = torch.cat([h_repeated1, h_repeated2], dim=-1)  # [batch_size, N, N, 2*out_features]\n",
    "\n",
    "        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(-1))  # [batch_size, N, N]\"\n",
    "        '''\n",
    "\n",
    "        time_embeddings = self.leakyrelu(torch.matmul(input, self.time_embedding)) # [batch_size, N, N]\n",
    "        embeddings = self.leakyrelu(torch.matmul(time_embeddings, self.node_embedding)) # [batch_size, N, in_features]\n",
    "\n",
    "        h = torch.matmul(embeddings, self.W)  # [batch_size, N, out_features]\n",
    "\n",
    "        h_repeated1 = h.unsqueeze(2).expand(-1, -1, N, -1)  # [batch_size, N, N, out_features]\n",
    "        h_repeated2 = h.unsqueeze(1).expand(-1, N, -1, -1)  # [batch_size, N, N, out_features]\n",
    "        a_input = torch.cat([h_repeated1, h_repeated2], dim=-1)  # [batch_size, N, N, 2*out_features]\n",
    "\n",
    "        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(-1))  # [batch_size, N, N]\"\n",
    "\n",
    "        if adj.dim() == 2:\n",
    "            adj = adj.unsqueeze(0).expand(batch_size, -1, -1)  # 扩展为 [batch_size, N, N]\n",
    "\n",
    "        zero_vec = -9e15 * torch.ones_like(e)\n",
    "        attention = torch.where(adj > 0, e, zero_vec)  # [batch_size, N, N]\n",
    "\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "\n",
    "        h_prime = torch.matmul(attention, h)  # [batch_size, N, out_features]\n",
    "\n",
    "        if self.concat:\n",
    "            return F.elu(h_prime)\n",
    "        else:\n",
    "            return h_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAF_model = GraphAttentionFuncLayer(seq_l, 1, node_l, 0.2, 0.2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAF_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAF_predict = GAF_model(occupancy, adj_dense_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAF_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
